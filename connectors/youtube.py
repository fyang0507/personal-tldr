"""
[GENERATED BY CURSOR]
YouTube Connector for fetching content from YouTube channels.

This module provides functionality to:
1. Check for updates from YouTube channels (first phase)
2. Retrieve cached content from YouTube channels (second phase)
3. Fetch channel IDs from channel names/handles
4. Filter videos based on duration requirements

The connector uses the YouTube Data API v3 and requires an API key.
See: https://developers.google.com/youtube/v3/docs/

Usage:
    from connectors.youtube import check_latest_updates, get_latest_update_details
    
    # Phase 1: Check for updates and cache data
    update_info = check_latest_updates("@channelname", api_key, duration_min=300)
    
    # Phase 2: Retrieve from cache when needed
    video_metadata = get_latest_update_details("@channelname")
    
    # Access video details
    video_title = video_metadata['title']
    video_url = video_metadata['url']
    video_duration = video_metadata['duration']
    view_count = video_metadata['stats']['view_count']

Note: The API key must have YouTube Data API v3 permissions enabled.
"""
from googleapiclient.discovery import build
from datetime import datetime
from dotenv import load_dotenv
import os
from utils.logging_config import logger
from typing import Dict, Any, Optional, Union
from utils.connector_cache import ConnectorCache

def generate_cache_key(channel_name: str) -> str:
    """
    Generate a standardized cache key for YouTube channel data.
    
    Args:
        channel_name: The name of the YouTube channel
        
    Returns:
        A standardized cache key
    """
    # Convert channel name to lowercase, remove @ if present, and replace spaces with underscores
    normalized_name = channel_name.lstrip('@').lower().replace(' ', '_')
    
    # Return the normalized name as the cache key
    # Note: The date will be added by ConnectorCache
    return normalized_name

def check_latest_updates(channel_name: str, api_key: str, duration_min: int = 300) -> Optional[Dict[str, Any]]:
    """
    Check for updates from a YouTube channel and cache the latest video metadata.
    
    Args:
        channel_name: YouTube channel name or handle (with or without '@')
        api_key: YouTube Data API key
        duration_min: Minimum duration in seconds for videos to include (default: 300, i.e., 5 minutes)
                     Set to 0 to include all videos regardless of duration
        
    Returns:
        Dict containing metadata for the latest video or None if error
    """
    # Initialize cache
    cache = ConnectorCache()
    cache_key = generate_cache_key(channel_name)
    
    try:
        # Get channel ID
        channel_id = get_channel_id_from_name(channel_name, api_key)
        if not channel_id:
            logger.error(f"Could not find channel ID for '{channel_name}'")
            return None
        
        # Get the latest video metadata
        metadata = get_latest_video_metadata(channel_id, api_key, duration_min)
        if not metadata:
            logger.warning(f"No suitable videos found for channel: {channel_name}")
            return None
        
        # Add channel information
        metadata["type"] = "youtube"
        metadata["channel"] = channel_name
        
        # Cache the result
        cache.save("youtube", cache_key, metadata)
        
        return metadata
        
    except Exception as e:
        logger.error(f"Error checking updates for YouTube channel '{channel_name}': {e}")
        return None

def get_latest_update_details(channel_name: str) -> Dict[str, Any]:
    """
    Get full content and metadata for the latest YouTube video from cache.
    Does not implement fetching logic - only retrieves from cache.
    
    Args:
        channel_name: Name of the YouTube channel
        
    Returns:
        Dict containing complete metadata for the latest video
        
    Raises:
        ValueError: If video not found in cache
    """
    if not channel_name:
        raise ValueError("Channel name is required to get video content from cache")
    
    # Try to get from cache
    cache = ConnectorCache()
    cache_key = generate_cache_key(channel_name)
    cached_data = cache.load("youtube", cache_key)
    
    # Check if we found cached data
    if cached_data:
        logger.info(f"Using cached data for YouTube channel: {channel_name}")
        return cached_data
    
    # If we reach here, the video was not in cache
    error_msg = f"No video found in cache for YouTube channel {channel_name}"
    logger.error(error_msg)
    raise ValueError(error_msg)

def get_channel_id_from_name(channel_name, api_key):
    """
    Get channel ID from channel name/handle
    
    Args:
        channel_name (str): YouTube channel name or handle (with or without '@')
        api_key (str): YouTube Data API key
    
    Returns:
        str: Channel ID or None if not found
    """
    try:
        # Remove @ symbol if present
        channel_name = channel_name.lstrip('@')
        
        youtube = build('youtube', 'v3', developerKey=api_key)
        
        # Search for the channel
        request = youtube.search().list(
            part='snippet',
            q=channel_name,
            type='channel',
            maxResults=1
        ).execute()
        
        if not request['items']:
            logger.warning(f"No channel found for name: {channel_name}")
            return None
            
        channel_id = request['items'][0]['id']['channelId']
        
        # Verify if this is the exact channel by checking the handle/name
        channel_response = youtube.channels().list(
            part='snippet',
            id=channel_id
        ).execute()
        
        if channel_response['items']:
            channel_info = channel_response['items'][0]['snippet']
            # Check if either custom URL or title matches
            if (channel_name.lower() in channel_info.get('customUrl', '').lower() or 
                channel_name.lower() in channel_info['title'].lower()):
                logger.info(f"Found channel ID: {channel_id} for channel: {channel_name}")
                return channel_id
                
        logger.warning(f"Found a channel but it doesn't match the requested name: {channel_name}")
        return None
        
    except Exception as e:
        logger.error(f"Error finding channel ID for {channel_name}: {str(e)}")
        return None


def get_latest_video_metadata(channel_id, api_key, duration_min=300):
    """
    Fetch metadata of the latest video from a YouTube channel
    
    Args:
        channel_id (str): The YouTube channel ID
        api_key (str): Your YouTube Data API key
        duration_min (int): Minimum duration in seconds for videos to include (default: 300, i.e., 5 minutes)
                            Set to 0 to include all videos regardless of duration
    
    Returns:
        dict: Video metadata or None if error occurs
    """
    try:
        logger.info(f"Fetching videos for channel ID: {channel_id} with min duration: {duration_min}s")
        # Create YouTube API client
        youtube = build('youtube', 'v3', developerKey=api_key)
        
        # First, get the uploads playlist ID of the channel
        channel_response = youtube.channels().list(
            part='contentDetails',
            id=channel_id
        ).execute()
        
        if not channel_response.get('items'):
            logger.error(f"Channel ID {channel_id} not found or has no content details")
            return None
            
        uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
        logger.info(f"Found uploads playlist ID: {uploads_playlist_id}")
        
        # Get videos from uploads playlist (fetch more to filter through if needed)
        max_results = 10 if duration_min > 0 else 1
        playlist_response = youtube.playlistItems().list(
            part='snippet',
            playlistId=uploads_playlist_id,
            maxResults=max_results
        ).execute()
        
        if not playlist_response['items']:
            logger.warning(f"No videos found in uploads playlist for channel ID: {channel_id}")
            return None
        
        # If not filtering by duration, just return the latest video
        if duration_min <= 0:
            logger.info("No duration filter applied, returning latest video")
            video_data = playlist_response['items'][0]['snippet']
            video_id = video_data['resourceId']['videoId']
            
            # Get video details
            video_details = youtube.videos().list(
                part='contentDetails,statistics',
                id=video_id
            ).execute()
        else:
            # Process videos to find the first one meeting the duration requirement
            videos_checked = 0
            for item in playlist_response['items']:
                videos_checked += 1
                video_data = item['snippet']
                video_id = video_data['resourceId']['videoId']
                
                logger.info(f"Checking video ID: {video_id}, Title: {video_data['title']}")
                
                # Get video details
                video_details = youtube.videos().list(
                    part='contentDetails,statistics,snippet',
                    id=video_id
                ).execute()
                
                if not video_details['items']:
                    logger.warning(f"Could not retrieve details for video ID: {video_id}")
                    continue
                
                # Parse ISO 8601 duration to seconds
                duration_str = video_details['items'][0]['contentDetails']['duration']
                duration_seconds = 0
                
                # Extract hours if present
                if 'H' in duration_str:
                    hours = int(duration_str.split('H')[0].split('T')[1])
                    duration_seconds += hours * 3600
                    duration_str = duration_str.split('H')[1]
                else:
                    duration_str = duration_str.split('T')[1]
                
                # Extract minutes if present
                if 'M' in duration_str:
                    minutes = int(duration_str.split('M')[0])
                    duration_seconds += minutes * 60
                    duration_str = duration_str.split('M')[1]
                
                # Extract seconds if present
                if 'S' in duration_str:
                    seconds = int(duration_str.split('S')[0])
                    duration_seconds += seconds
                
                logger.info(f"Video '{video_data['title']}' has duration: {duration_seconds}s (requirement: {duration_min}s)")
                
                # Check if video meets the minimum duration requirement
                if duration_seconds >= duration_min:
                    # Check for #Shorts hashtag as an additional filter
                    title = video_details['items'][0]['snippet']['title'].lower()
                    description = video_details['items'][0]['snippet']['description'].lower()
                    has_shorts_hashtag = '#shorts' in title or '#shorts' in description or '#short' in title or '#short' in description
                    
                    if has_shorts_hashtag:
                        logger.info(f"Video '{video_data['title']}' has required duration but contains #shorts hashtag")
                    
                    # If it meets duration requirement and doesn't have shorts hashtag, use this video
                    if not has_shorts_hashtag:
                        logger.info(f"Found eligible video: '{video_data['title']}' with duration {duration_seconds}s")
                        break
            else:
                # If we've gone through all items and none meet criteria, return None
                logger.warning(f"No video found with duration >= {duration_min} seconds after checking {videos_checked} videos")
                return None
        
        # Combine video data and statistics
        metadata = {
            'title': video_data['title'],
            'description': video_data['description'],
            'published_at': datetime.strptime(video_data['publishedAt'], '%Y-%m-%dT%H:%M:%SZ').date().isoformat(),
            'video_id': video_id,
            'url': f'https://www.youtube.com/watch?v={video_id}',
            'thumbnail_url': video_data['thumbnails']['default']['url'],
            'duration': video_details['items'][0]['contentDetails']['duration'],
            'stats': {
                'view_count': video_details['items'][0]['statistics'].get('viewCount', 'N/A'),
                'like_count': video_details['items'][0]['statistics'].get('likeCount', 'N/A'),
                'comment_count': video_details['items'][0]['statistics'].get('commentCount', 'N/A'),
            }
        }
        
        logger.info(f"Successfully retrieved metadata for video: {video_id}")
        return metadata
        
    except Exception as e:
        logger.error(f"An error occurred while fetching video metadata: {str(e)}")
        return None

def main():
    """Example demonstrating the two-phase YouTube content retrieval approach."""
    # Load API key from environment
    load_dotenv()
    API_KEY = os.getenv('YOUTUBE_API_KEY')
    
    # Example YouTube channel
    channel_name = "@entreprenuership_opportunities"
    
    print(f"Demonstrating two-phase approach for YouTube channel: {channel_name}")
    
    # PHASE 1: Check for updates
    print("\n=== Phase 1: Check for updates ===")
    print("In this phase, we check for new videos and cache complete data.")
    latest = check_latest_updates(channel_name, API_KEY, duration_min=300)
    
    if not latest:
        print("No suitable videos found")
        return
        
    print(f"Found latest video: {latest['title']}")
    print(f"Published: {latest['published_at']}")
    print(f"URL: {latest['url']}")
    
    # PHASE 2: Get full content from cache
    print("\n=== Phase 2: Get content from cache ===")
    print("In this phase, we retrieve the full content from cache without re-fetching.")
    try:
        full_content = get_latest_update_details(channel_name)
        print(f"Retrieved from cache: {full_content['title']}")
        print(f"Duration: {full_content.get('duration', 'N/A')}")
        print(f"URL: {full_content['url']}")
        print(f"View Count: {full_content['stats'].get('view_count', 'N/A')}")
        print(f"Comment Count: {full_content['stats'].get('comment_count', 'N/A')}")
    except ValueError as e:
        print(f"Error retrieving from cache: {e}")

if __name__ == "__main__":
    main()
