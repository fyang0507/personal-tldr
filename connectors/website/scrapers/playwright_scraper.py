"""
[GENERATED BY CURSOR]
Playwright Website Scraper

This module implements a website scraper using Playwright, a library for browser
automation. It is designed to handle websites that require JavaScript execution
for rendering content or employ anti-bot protection measures that simpler HTTP
request-based scrapers cannot bypass.

The primary function exposed for external use is `scrape(url: str)`.
This function scrapes the HTML content of the specified URL using a headless browser (Chromium)
and is a synchronous wrapper around the asynchronous core logic.
It handles JavaScript execution, scrolling, and simulated human interaction.

Key Behaviors:
- Uses a common User-Agent string and viewport settings.
- Simulates page scrolling to trigger lazy-loaded content.
- Introduces random delays to mimic human behavior.
- Handles basic navigation and waits for network activity to settle.

Dependencies:
- Playwright (`pip install playwright`)
- Playwright browser drivers (`playwright install`)
"""

from pathlib import Path
from utils.logging_config import logger
import random
from typing import Optional, Tuple
import asyncio
from .base import BaseScraper


async def _simulate_browser(url: str) -> Tuple[Optional[str], Optional[str]]:
    """
    Simulates a browser using Playwright to bypass anti-bot protection.
    
    Args:
        url: URL to scrape
        
    Returns:
        tuple: (html_content, page_title) or (None, None) if an error occurs
    """
    try:
        from playwright.async_api import async_playwright
        
        logger.info(f"Starting Playwright browser simulation for: {url}")
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
                viewport={"width": 1280, "height": 800}
            )
            page = await context.new_page()
            await page.set_extra_http_headers({
                "Accept-Language": "en-US,en;q=0.9",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            })
            
            logger.info(f"Playwright navigating to {url}")
            response = await page.goto(url, wait_until="networkidle", timeout=60000)
            
            if not response or response.status >= 400:
                status = response.status if response else "N/A"
                logger.error(f"Playwright failed to load {url} (status: {status})")
                await browser.close()
                return None, None
            
            await page.wait_for_timeout(random.randint(2000, 4000))
            
            await page.evaluate(""" 
                async () => {
                    await new Promise((resolve) => {
                        let totalHeight = 0;
                        const distance = 300;
                        const timer = setInterval(() => {
                            const scrollHeight = document.body.scrollHeight;
                            window.scrollBy(0, distance);
                            totalHeight += distance;
                            
                            if(totalHeight >= scrollHeight){
                                clearInterval(timer);
                                resolve();
                            }
                        }, 100);
                    });
                }
            """)
            await page.wait_for_timeout(random.randint(1000, 2000))
            
            html_content = await page.content()
            page_title = await page.title()
            logger.info(f"Playwright successfully retrieved content for {url} (title: {page_title})")
            await browser.close()
            return html_content, page_title
            
    except ImportError:
        logger.error("Playwright not installed. Run: pip install playwright && playwright install")
        return None, None
    except Exception as e:
        logger.error(f"Error in Playwright browser simulation for {url}: {e}", exc_info=True)
        return None, None

class PlaywrightScraper(BaseScraper):
    """
    A scraper that uses Playwright to fetch HTML content from dynamic websites.
    """

    async def _scrape_async(self, url: str) -> Optional[str]:
        """
        Asynchronously scrapes a website using Playwright.
        """
        try:
            html_content, _ = await _simulate_browser(url)
            if not html_content:
                logger.warning(f"No HTML content fetched from {url} using Playwright.")
                return None
            return html_content
        except Exception as e:
            logger.error(f"Error in PlaywrightScraper._scrape_async for {url}: {e}", exc_info=True)
            return None

    def scrape(self, url: str) -> Optional[str]:
        """
        Synchronously scrapes a website using Playwright.
        
        Args:
            url: URL to scrape
            
        Returns:
            str: HTML content as a string, or None if an error occurs
        """
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(self._scrape_async(url))

def main():
    """Main function with placeholder values."""
    target_url = "https://36kr.com/p/3265228187942663"
    output_dir = "data/36kr"
    
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    html_path = Path(output_dir) / f"demo_playwright_scraper.html"
    
    scraper = PlaywrightScraper()
    html_content = scraper.scrape(url=target_url)
    
    if html_content:
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        logger.success(f"Saved Playwright scraped HTML to {html_path}")
    else:
        logger.error(f"Failed to scrape {target_url} using Playwright.")

if __name__ == "__main__":
    main() 