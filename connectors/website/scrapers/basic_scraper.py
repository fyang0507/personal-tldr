"""
[GENERATED BY CURSOR]
Script to scrape websites using the requests library.
Provides basic scraping functionality for sites without anti-bot protection.
"""

import requests
from pathlib import Path
from utils.logging_config import logger
from typing import Optional


def fetch_webpage(url: str):
    """
    Fetches a webpage using the requests library.
    
    Args:
        url: URL to scrape
        
    Returns:
        tuple: (html_content, status_code) or (None, None) if an error occurs
    """
    try:
        logger.info(f"Fetching webpage: {url}")
        
        # Set headers to mimic a browser
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.9",
        }
        
        # Fetch the webpage
        response = requests.get(url, headers=headers, timeout=30)
        
        # Check if the request was successful
        if response.status_code >= 400:
            logger.error(f"Got HTTP error {response.status_code} for {url}")
            return None, response.status_code
        
        logger.info(f"Successfully fetched {url} with status code: {response.status_code}")
        return response.text, response.status_code
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Error fetching {url}: {e}")
        return None, None


def scrape(url: str) -> Optional[str]:
    """
    Scrapes a website using requests and returns the HTML content.
    
    Args:
        url: URL to scrape
        
    Returns:
        str: HTML content as a string, or None if an error occurs.
    """
    try:
        # Step 1: Fetch HTML content
        html_content, status_code = fetch_webpage(url)
        
        if not html_content:
            logger.warning(f"No HTML content fetched from {url} by basic scraper.")
            return None
            
        # Step 2: Just return the HTML content
        return html_content
            
    except Exception as e:
        logger.error(f"Error in basic scrape for {url}: {e}", exc_info=True)
        return None


def main():
    """Main function with placeholder values."""
    # Target URL from the user
    target_url = "https://36kr.com/user/5294208"
    output_dir = "data/36kr"
    
    # Ensure output directory exists
    Path(output_dir).mkdir(parents=True, exist_ok=True)
        
    html_path = Path(output_dir) / f"demo_basic_scraper.html"
    
    # Scrape website
    html_content = scrape(
        url=target_url
    )
    
    if html_content:
        # Save HTML
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        logger.success(f"Saved HTML content to {html_path}")
    else:
        logger.error("Failed to scrape the website.")


if __name__ == "__main__":
    main() 