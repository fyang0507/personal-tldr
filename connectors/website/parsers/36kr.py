"""
[GENERATED BY CURSOR]
36kr.com Parser Module

This module provides parsing capabilities specifically tailored for articles and
catalogue pages from 36kr.com. It uses BeautifulSoup to navigate the HTML structure
and extract relevant information.

Note: The selectors used in this parser are specific to the observed HTML structure
of 36kr.com and may require updates if the website's layout changes.
"""

import json
from utils.logging_config import logger
from bs4 import BeautifulSoup
from pathlib import Path
from typing import Optional, Dict, List, Any # Added List and Any
from .base import BaseParser # Import the base class

class Kr36Parser(BaseParser):
    """
    Parser for 36kr.com content.

    Implements methods to extract article catalogues and individual article content
    from 36kr HTML.
    """

    def extract_catalogue(self, html_content: str, base_url: Optional[str] = None) -> Optional[str]: # Return type is str (JSON)
        """
        Parses HTML content from a 36kr catalog-like page to extract article details.

        Args:
            html_content: The HTML content of the page.
            base_url: The base URL to prepend to relative article URLs (e.g., "https://36kr.com").
                      Required by this parser.

        Returns:
            Optional[str]: A JSON string representing a list of dictionaries,
                           where each dictionary contains 'title', 'url', 'published_date'.
                           Returns None if base_url is not provided or if parsing fails.
                           Returns an empty list (as JSON string) if no articles found.
        """
        if not base_url:
            logger.error("base_url is required for Kr36Parser.extract_catalogue but was not provided.")
            return None

        articles: List[Dict[str, str]] = []
        if not html_content:
            logger.warning("Received empty HTML content for 36kr catalogue.")
            return json.dumps(articles, ensure_ascii=False, indent=2)

        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            article_items = soup.select('div.flow-item div.kr-flow-article-item')

            if not article_items:
                if soup.body:
                    logger.info("No article items found using selector 'div.flow-item div.kr-flow-article-item' on 36kr.")
                else:
                    logger.warning("HTML content for 36kr catalogue seems empty or invalid, no body tag found.")
                return json.dumps(articles, ensure_ascii=False, indent=2)

            for item_idx, item in enumerate(article_items):
                title_tag = item.select_one('a.article-item-title')
                date_tag = item.select_one('div.kr-flow-bar span.kr-flow-bar-time')
                
                title = None
                url = None
                published_date = None

                if title_tag:
                    title = title_tag.get_text(strip=True)
                    raw_url = title_tag.get('href')
                    if raw_url:
                        if raw_url.startswith(('http://', 'https://')):
                            url = raw_url
                        else:
                            url = f"{base_url.rstrip('/')}/{raw_url.lstrip('/')}"
                
                if date_tag:
                    date_contents = list(date_tag.stripped_strings)
                    if date_contents:
                        published_date = date_contents[-1]
                    else:
                        published_date_direct_text = date_tag.get_text(strip=True)
                        if published_date_direct_text:
                            published_date = published_date_direct_text
                        else:
                            logger.debug(f"36kr Article item {item_idx}: Date tag found but no text content: {str(date_tag)[:100]}")

                if title and url and published_date:
                    articles.append({
                        'title': title,
                        'url': url,
                        'published_date': published_date
                    })
                else:
                    if title_tag or date_tag:
                        missing_parts = []
                        if not title: missing_parts.append("title")
                        if not url: missing_parts.append("url")
                        if not published_date: missing_parts.append("date")
                        logger.warning(
                            f"36kr Article item {item_idx}: Partial data. Missing: {', '.join(missing_parts) or 'unknown'}. "
                            f"Item snippet: {str(item)[:200]}"
                        )

            if not articles and article_items:
                 logger.warning("36kr: HTML elements matched article selectors, but no complete article entries parsed.")
                
            logger.success(f"36kr parser: Successfully parsed {len(articles)} articles from catalogue.")
            
        except Exception as e:
            logger.error(f"Error during 36kr HTML parsing for articles: {e}", exc_info=True)
            # Fall through to return json.dumps of potentially empty articles list
        
        return json.dumps(articles, ensure_ascii=False, indent=2)

    def extract_content(self, html_content: str) -> Optional[Dict[str, str]]:
        """
        Parses HTML content from a 36kr article page to extract its title and main content.

        Args:
            html_content: The HTML content of the article page.

        Returns:
            A dictionary containing 'title' and 'content', or None if parsing fails.
        """
        if not html_content:
            logger.warning("Received empty HTML content for 36kr content extraction.")
            return None

        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            title_tag = soup.select_one('h1.article-title.common-width')
            title = title_tag.get_text(strip=True) if title_tag else None

            content_div = soup.select_one('div.articleDetailContent')
            content_text = content_div.get_text(separator='\n', strip=True) if content_div else None

            if title and content_text:
                logger.success(f"36kr parser: Successfully extracted article content.")
                return {
                    'title': title,
                    'content': content_text
                }
            else:
                missing_parts = []
                if not title: missing_parts.append("title (h1.article-title.common-width)")
                if not content_text: missing_parts.append("content (div.articleDetailContent)")
                logger.warning(f"36kr: Could not extract full article content. Missing: {', '.join(missing_parts)}")
                return None

        except Exception as e:
            logger.error(f"Error during 36kr HTML parsing for article content: {e}", exc_info=True)
            return None


# Test functions updated to use Kr36Parser instance
def _test_extract_catalogue():
    """Tests the Kr36Parser.extract_catalogue method."""

    parser = Kr36Parser()
    base_url_catalogue = "https://36kr.com"
    html_file_path_catalogue = Path("data/36kr/demo_gateway.html")
    logger.info(f"Attempting to read HTML content from {html_file_path_catalogue}")

    try:
        html_content_catalogue = html_file_path_catalogue.read_text(encoding='utf-8')
        extracted_articles_catalogue = parser.extract_catalogue(html_content_catalogue, base_url_catalogue)

        if extracted_articles_catalogue is not None: # Check for None explicitly
            logger.info(f"Extracted articles (catalogue JSON): \n{extracted_articles_catalogue}")
            try:
                parsed_catalogue = json.loads(extracted_articles_catalogue)
                if isinstance(parsed_catalogue, list) and len(parsed_catalogue) > 0:
                    logger.info(f"Successfully parsed {len(parsed_catalogue)} articles from catalogue.")
                elif isinstance(parsed_catalogue, list) and len(parsed_catalogue) == 0 and html_content_catalogue:
                    logger.info("Catalogue extraction resulted in an empty list of articles.")
                else:
                     logger.warning("Catalogue extraction did not result in a list of articles or list was empty unexpectedly.")
            except json.JSONDecodeError:
                logger.error("Failed to parse JSON output from extract_catalogue method.")
        else: 
            logger.error("Catalogue extraction failed and returned None (e.g. base_url missing or major error in Kr36Parser.extract_catalogue).")
    except FileNotFoundError:
        logger.error(f"Catalogue HTML file not found: {html_file_path_catalogue}")
    except Exception as e:
        logger.error(f"An error occurred during catalogue extraction test: {e}", exc_info=True)


def _test_extract_content():
    """Tests the Kr36Parser.extract_content method."""

    parser = Kr36Parser()
    html_file_path_content = Path("data/36kr/demo_content.html")
    logger.info(f"Attempting to read HTML content from {html_file_path_content}")

    try:
        html_content_article = html_file_path_content.read_text(encoding='utf-8')
        extracted_main_content = parser.extract_content(html_content_article)

        if extracted_main_content and extracted_main_content.get('title') and extracted_main_content.get('content'):
            logger.info(f"Extracted Article Title: {extracted_main_content['title']}")
            logger.info(f"Extracted Article Content (first 200 chars):\n{extracted_main_content['content'][:200]}...")
        else:
            logger.warning("No main content (title and/or text) was extracted from the article HTML content using Kr36Parser.")
            if extracted_main_content is not None: 
                 logger.debug(f"Extraction result from Kr36Parser: Title present: {bool(extracted_main_content.get('title'))}, Content present: {bool(extracted_main_content.get('content'))}")
    except FileNotFoundError:
        logger.error(f"Article content HTML file not found: {html_file_path_content}")
    except Exception as e:
        logger.error(f"An error occurred during article content extraction test: {e}", exc_info=True)


def main():
    logger.info("Part 1: Test Kr36Parser.extract_catalogue method...")
    _test_extract_catalogue()
    logger.info("\n" + "="*50 + "\n")
    logger.info("Part 2: Test Kr36Parser.extract_content method...")
    _test_extract_content()

if __name__ == "__main__":
    main() 