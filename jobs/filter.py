"""
[GENERATED BY CURSOR]
This script filters raw results by comparing with the current.json file.
It identifies new entries and exports them to a filtered_results file with today's date.
When running in GitHub Actions, it reads from and writes to a GitHub Gist instead.
"""

import json
from datetime import datetime
import os
from loguru import logger
from dotenv import load_dotenv
from connectors.gist import read_from_gist, update_gist

def is_github_actions_env():
    return os.getenv("GITHUB_ACTIONS") == "true"

def filter_new_entries(raw_results, current_entries):
    """
    Filter raw results to keep only new entries that are not in current_entries.
    Returns a tuple of (filtered_results, updated_current_entries).
    """
    # Create a set of (channel, published_at) tuples from current entries for efficient lookup
    current_set = {(entry['channel'], entry['published_at']) for entry in current_entries}
    
    # Filter raw results to keep only new entries
    filtered_results = []
    for item in raw_results:
        channel = item['channel']
        published_at = item['published_at']
        
        # Check if this entry is not in current_entries
        # TODO: only need to retain the latest entry for each channel
        if (channel, published_at) not in current_set:
            filtered_results.append(item)
            # Add the new entry to current_entries
            current_entries.append({
                'channel': channel,
                'published_at': published_at
            })
            logger.info(f"Adding {channel} on {published_at}")
        else:
            logger.info(f"Skipping {channel} on {published_at} because it already exists")
    
    return filtered_results, current_entries

def load_raw_results(today):
    """
    Load raw results from the daily JSON file.
    Returns the raw results data or None if the file doesn't exist.
    """
    raw_results_path = f"data/raw_results_{today}.json"
    
    # Check if raw results file exists
    if not os.path.exists(raw_results_path):
        logger.error(f"Error: {raw_results_path} does not exist.")
        return None
    
    # Load raw results
    with open(raw_results_path, 'r', encoding='utf-8') as f:
        raw_results = json.load(f)
    
    return raw_results

def save_filtered_results(filtered_results, today):
    """Save filtered results to a local file"""
    # Ensure the data directory exists
    os.makedirs("data", exist_ok=True)
    
    # Define path for filtered results
    filtered_results_path = f"data/filtered_results_{today}.json"
    
    # Write filtered results to a new file
    with open(filtered_results_path, 'w', encoding='utf-8') as f:
        json.dump(filtered_results, f, ensure_ascii=False, indent=2)
    
    logger.info(f"Results saved to {filtered_results_path}")

def main():
    # Get today's date in the format YYYY-MM-DD
    today = datetime.now().strftime("%Y-%m-%d")
    
    # Load environment variables
    load_dotenv()
    
    # Load raw results
    raw_results = load_raw_results(today)
    if raw_results is None:
        return
    
    # Check if running in GitHub Actions
    if is_github_actions_env():
        logger.info("Running in GitHub Actions environment")
        
        # Get Gist ID and GitHub token from environment variables
        gist_id = os.getenv("GIST_ID")
        gist_token = os.getenv("GIST_TOKEN")
        
        if not gist_id:
            logger.error("Missing GIST_ID in environment variables")
            return
        
        # Load current entries from Gist
        try:
            current_entries = read_from_gist(gist_id, gist_token, "current.json")
        except Exception as e:
            logger.error(f"Error reading from gist: {e}")
            return
        
        # Filter raw results and get updated current entries
        filtered_results, updated_current_entries = filter_new_entries(raw_results, current_entries)
        
        # Save filtered results locally
        save_filtered_results(filtered_results, today)
        
        # Update both files in the gist
        try:
            files_data = {
                "current.json": {
                    "content": json.dumps(updated_current_entries, ensure_ascii=False, indent=2)
                },
                # TODO: this can be removed after testing
                f"filtered_results_{today}.json": {
                    "content": json.dumps(filtered_results, ensure_ascii=False, indent=2)
                }
            }
            update_gist(gist_id, gist_token, files_data)
            logger.info("Updated gist with current entries and filtered results")
        except Exception as e:
            logger.error(f"Error updating gist: {e}")
            return
        
        logger.info(f"Filtered {len(filtered_results)} new entries out of {len(raw_results)} total.")
    
    else:
        logger.info("Running in local development environment")
        
        # Define file path for current entries
        current_path = "data/current.json"
        
        # Check if current.json exists
        if not os.path.exists(current_path):
            logger.error(f"Error: {current_path} does not exist.")
            return
        
        # Load current entries
        with open(current_path, 'r', encoding='utf-8') as f:
            current_entries = json.load(f)
        
        # Filter raw results and get updated current entries
        filtered_results, updated_current_entries = filter_new_entries(raw_results, current_entries)
        
        # Save filtered results locally
        save_filtered_results(filtered_results, today)

        # Update current.json with the new entries
        with open(current_path, 'w', encoding='utf-8') as f:
            json.dump(updated_current_entries, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Filtered {len(filtered_results)} new entries out of {len(raw_results)} total.")

if __name__ == "__main__":
    main()
