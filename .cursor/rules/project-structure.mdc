---
description: wavelength project structure
globs: 
alwaysApply: true
---
# Project Structure Guide

This project is organized into these main directories:

## Connectors

The [connectors/](mdc:connectors) directory contains individual connectors that link to different external sources:

- [YouTube](mdc:connectors/youtube.py) - YouTube video content processing
- [Podcast](mdc:connectors/podcast.py) - Podcast audio content processing
- [Notion](mdc:connectors/notion.py) - Notion document integration
- [Newsletter](mdc:connectors/newsletter.py) - Email newsletter processing (HTML)
- [Newsletter Plain](mdc:connectors/newsletter_plain.py) - Plain text newsletter processing
- [Bilibili](mdc:connectors/bilibili.py) - Bilibili video platform integration
- [LLM](mdc:connectors/llm.py) - Language model integration
- [Gist](mdc:connectors/gist.py) - GitHub Gist integration
- [Website](mdc:connectors/website) - Website content extraction. This module is further organized into:
    - [Pipeline](mdc:connectors/website/pipeline.py) - Orchestrates website content retrieval using a two-phase approach (update checking and content detailing).
    - [Parsers](mdc:connectors/website/parsers) - Contains specific parser implementations for different websites.
        - [Generic Parser](mdc:connectors/website/parsers/generic.py) - A generic parser, often relying on LLMs.
        - [36kr Parser](mdc:connectors/website/parsers/36kr.py) - Parser specific to 36kr.com.
    - [Scrapers](mdc:connectors/website/scrapers) - Contains different scraping mechanisms.
        - [Basic Scraper](mdc:connectors/website/scrapers/basic_scraper.py) - A simple scraper using HTTP requests.
        - [Playwright Scraper](mdc:connectors/website/scrapers/playwright_scraper.py) - A scraper using Playwright for dynamic content.

Each connector implements functionality to fetch and process data from its respective source.

## Jobs

The [jobs/](mdc:jobs) directory is used for orchestration and building workflows:

- [Fetch Content](mdc:jobs/fetch_content.py) - Fetches content from various sources
- [Check Update](mdc:jobs/check_update.py) - Checks for updates from sources
- [Preprocess](mdc:jobs/preprocess.py) - Data preparation and transformation
- [Filter](mdc:jobs/filter.py) - Content filtering and selection
- [Curate](mdc:jobs/curate.py) - Content curation and organization
- [Publish](mdc:jobs/publish.py) - Content publishing and distribution

These jobs work together to create complete data processing pipelines.

## Utils

The [utils/](mdc:utils) directory contains utility functions and helpers:

- [Connector Cache](mdc:utils/connector_cache.py) - Caching utilities for connectors
- [Toml Loader](mdc:utils/toml_loader.py) - Configuration loading utilities
- [Logging Config](mdc:utils/logging_config.py) - Logging configuration
- [Read Time Estimate](mdc:utils/read_time_estimate.py) - Estimates reading time for content
- [LLM Response Format](mdc:utils/llm_response_format.py) - Utilities for parsing LLM responses

## Prompts

The [prompts/](mdc:prompts) directory contains prompt templates for LLM interactions:

- [Curator](mdc:prompts/curator.toml) - Prompts for content curation
- [Preprocess](mdc:prompts/preprocess.toml) - Prompts for content preprocessing
- [Website](mdc:prompts/website.toml) - Prompts for website content extraction

## Project Configuration

- [subscriptions.toml](mdc:subscriptions.toml) - Source configurations and subscriptions
- [requirements.txt](mdc:requirements.txt) - Project dependencies